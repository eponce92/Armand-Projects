# CLIP Image Search ğŸ”

A modern web application that uses OpenAI's CLIP model to find visually similar images in your local folders. Built with FastAPI and modern web technologies.

## âœ¨ Features

- ğŸ¯ AI-powered visual similarity search using CLIP
- ğŸ–¼ï¸ Modern, responsive gallery with masonry layout
- ğŸ¨ Professional UI with glass morphism effects
- ğŸ”„ Real-time image preview and batch processing
- ğŸ“Š Adjustable similarity threshold with visual feedback
- ğŸ›ï¸ Customizable batch size for performance
- ğŸ“± Fully responsive design
- âŒ¨ï¸ Keyboard navigation support
- ğŸ–±ï¸ Drag and drop support
- ğŸ” Image content analysis
- ğŸ’¾ Session persistence

## ğŸ¨ UI Features

- Modern glass morphism design
- Smooth animations and transitions
- Interactive slider controls
- Professional color scheme
- Responsive image gallery
- Immersive image viewer
- Loading states and feedback
- Native folder picker integration

## ğŸ› ï¸ Technology Stack

### Frontend

- HTML5 & CSS3
- Modern JavaScript (ES6+)
- Bootstrap 5
- Masonry.js for gallery layout
- IonIcons for icons
- Custom animations and transitions

### Backend

- FastAPI
- Python 3.8+
- OpenAI CLIP model
- PIL for image processing
- TorchVision
- Async processing

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- Modern web browser
- CUDA-capable GPU (recommended)

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/clip-image-search.git
   cd clip-image-search
   ```

2. Create and activate a virtual environment:

   ```bash
   python -m venv venv

   # On Windows:
   .\venv\Scripts\activate

   # On Unix or MacOS:
   source venv/bin/activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Running the Application

1. Start the server:

   ```bash
   uvicorn backend.main:app --reload
   ```

2. Open your browser and navigate to:
   ```
   http://localhost:8000
   ```

## ğŸ’¡ Usage

1. **Select Query Image**

   - Click or drag an image to the upload area
   - Preview appears automatically

2. **Choose Search Location**

   - Use the "Browse" button to select a folder
   - All supported image formats will be searched

3. **Adjust Settings**

   - Set minimum similarity score (0.0 - 1.0)
   - Choose batch size based on your hardware
   - Larger batch sizes are faster but use more memory

4. **View Results**
   - Results appear in a responsive gallery
   - Sorted by similarity score
   - Click any image for full-screen view
   - Use arrow keys to navigate in full-screen mode

## ğŸ—‚ï¸ Project Structure

```
clip-image-search/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â””â”€â”€ clip_utils.py     # CLIP model utilities
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/       # Modular UI components
â”‚   â”œâ”€â”€ index.html       # Main HTML
â”‚   â”œâ”€â”€ script.js        # Main JavaScript
â”‚   â””â”€â”€ styles.css       # Main styles
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

The application can be configured through several parameters:

- **Batch Size**:

  - Small (16 images)
  - Medium (32 images) - default
  - Large (64 images)

- **Similarity Score**:
  - Range: 0.0 to 1.0
  - Default: 0.2
  - Higher values = stricter matching

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'âœ¨ Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI for the CLIP model
- FastAPI team
- Bootstrap team
- Masonry.js contributors
- IonIcons team
